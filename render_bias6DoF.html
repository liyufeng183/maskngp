<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Renderer</title>
    <meta charset="UTF-8" />

    <meta
      name="viewport"
      content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0"
    />

    <style>
      body,
      div {
        margin: 0;
        padding: 0;
      }
      .renderer {
        border: dashed #000000;
      }
    </style>
  </head>

  <body>
    <div
      id="container"
      style="display: flex; justify-content: center; align-items: center"
    ></div>
    <div id="progressBar" style="text-align: center"></div>
  </body>

  <script type="module">
    import * as THREE from "https://unpkg.com/three?module";
    import WebGL from "https://unpkg.com/three/examples/jsm/capabilities/WebGL.js?module";
    import { OBJLoader } from "https://unpkg.com/three/examples/jsm/loaders/OBJLoader.js?module";
    import { OrbitControls } from "https://unpkg.com/three/examples/jsm/controls/OrbitControls.js?module";
    import Stats from "https://unpkg.com/three/examples/jsm/libs/stats.module.js?module";
    import { GUI } from "https://unpkg.com/three/examples/jsm/libs/lil-gui.module.min.js?module";

    // const BASE =
    //   "https://huggingface.co/ashawkey/nerf2mesh/resolve/main/scenes/"; // remote
    //   "https://huggingface.co/ashawkey/nerf2mesh"; // remote
    //const BASE = "./"; // local
    const BASE="https://huggingface.co/xiongdi/maskngp/resolve/main/scenes/";
    // const BASE = "https://huggingface.co/xiongdi/maskngp/resolve/main/scenes/";// local

    // shaders
    const RenderVertShader = `
    in vec3 position;  // 输入的顶点位置
    in vec2 uv;        // 输入的UV坐标

    out vec2 vUv;      // 输出的UV坐标,将被传递到片元着色器
    // out vec3 rayDirection; // 输出的射线方向，将被传递到片元着色器
    out vec3 positionF;
    out vec3 cameraPos;
    out mat4 modelPos;
    uniform mat4 modelViewMatrix; // 模型视图矩阵（将模型空间的顶点位置转换到视图空间）
    uniform mat4 projectionMatrix;  // 投影矩阵（将视图空间的顶点位置转换到裁剪空间）
    uniform mat4 modelMatrix;        // 模型矩阵（将模型空间的顶点位置转换到世界空间）
    uniform vec3 cameraPosition; // 摄像机的位置

    void main() {
        vUv = uv; // 将输入的UV坐标传递到片元着色器
        gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 ); // 计算裁剪空间的顶点位置
        // rayDirection = (  cameraPosition-(modelMatrix * vec4( position, 1.0 )).rgb ); // 计算从摄像机位置到世界空间的顶点位置的射线方向
        positionF=position;
        cameraPos= cameraPosition;
        modelPos=modelMatrix;
        // nomalM=normalMatrix;

    }
    `;
    //需要注意的是，这个着色器假设所有输入的顶点属性（如位置、UV坐标和法线）都已经在模型空间中。这意味着如果模型进行了变换
    //（如旋转、缩放或平移），这些变换已经应用到了这些属性上。如果模型的变换存储在模型矩阵中，
    //并且模型的顶点属性是相对于模型的本地坐标系的，那么你可能需要在计算Normal和rayDirection之前应用模型矩阵。
    const RenderFragShader_template = `
precision highp float;  // 设置浮点数的精度为高精度

layout(location = 0) out vec4 pc_FragColor;  // 输出的颜色值

in vec2 vUv;  // 从顶点着色器接收的UV坐标
in mat4 modelPos;
// in vec3 rayDirection;  // 从顶点着色器接收的射线方向
in vec3 positionF;
in vec3 cameraPos;
uniform int mode;  // 渲染模式
uniform highp sampler2D Diffuse;  // diff纹理
uniform highp sampler2D hash1;//specular 特征


uniform highp sampler2D weightsZero;  // 第一层神经网络的权重,已经存储为sampler2D的纹理采样器格式
uniform highp sampler2D weightsOne;  // 第二层神经网络的权重
uniform highp sampler2D BiasZero;  // 第一层神经网络的偏移
uniform highp sampler2D BiasOne;  // 第二层神经网络的偏移
#define PI 3.14159265358979323846


float[21] frencode(vec3 dir, int degree) {//返回编码完成后的dir数组(39)
    float[21] result;//3*6*2+3
    result[0]=dir.x;
    result[1]=dir.y;
    result[2]=dir.z;
    
    for (int i = 0; i <3; ++i) {
    float valx = pow(2.0, float(i))  * (dir.x);
    float valy = pow(2.0, float(i))  * (dir.y);
    float valz = pow(2.0, float(i))  * (dir.z);

        //sin,cos交替
        // result[i*degree+3]=sin(valx);
        // result[i*degree+3+1]=cos(valx);
        // result[i*degree+3+2]=sin(valy);
        // result[i*degree+3+3]=cos(valy);
        // result[i*degree+3+4]=sin(valz);
        // result[i*degree+3+5]=cos(valz);
      //先sin,再cos
        result[i*6+3]=sin(valx);
        result[i*6+3+1]=sin(valy);
        result[i*6+3+2]=sin(valz);
        result[i*6+3+3]=cos(valx);
        result[i*6+3+4]=cos(valy);
        result[i*6+3+5]=cos(valz);
      //交错进行
        // result[i*degree+3]=sin(valx);
        // result[i*degree+3+1]=cos(valy);
        // result[i*degree+3+2]=sin(valz);
        // result[i*degree+3+3]=cos(valx);
        // result[i*degree+3+4]=sin(valy);
        // result[i*degree+3+5]=cos(valz);

        // result[i*degree+3]=cos(valx);
        // result[i*degree+3+1]=sin(valy);
        // result[i*degree+3+2]=cos(valz);
        // result[i*degree+3+3]=sin(valx);
        // result[i*degree+3+4]=cos(valy);
        // result[i*degree+3+5]=sin(valz);
    }
    
    return result;
}





// evaluateNetwork(hash_feature, normalize(rayDirection),normal)
vec3 evaluateNetwork(float[3] hash, vec3 dir) {

    // NUM_CHANNELS_ZERO (input_dim) is hard-coded as 6->47
    // NUM_CHANNELS_ONE (hidden_dim) can vary, but should be divisible by 4  32->64
    // NUM_CHANNELS_TWO (output_dim) is hard-coded as 3
    mat4 w;
    vec4 v;
    vec4 bias;
    
    v = vec4(dir[0],dir[1],dir[2],hash[0]);
    vec4 result_one[NUM_CHANNELS_ONE / 4];
    
    for (int i = 0; i < NUM_CHANNELS_ONE; i += 4) {
            w = mat4(
                texelFetch(weightsZero, ivec2(0,i), 0),
                texelFetch(weightsZero, ivec2(0,i + 1), 0),
                texelFetch(weightsZero, ivec2(0,i + 2), 0),
                texelFetch(weightsZero, ivec2(0,i + 3), 0)
            );   
            bias=vec4(
              texelFetch(BiasZero, ivec2(0,i), 0).r,
              texelFetch(BiasZero, ivec2(0,i+1), 0).r,
              texelFetch(BiasZero, ivec2(0,i+2), 0).r,
              texelFetch(BiasZero, ivec2(0,i+3), 0).r
            );      
            result_one[i / 4] += v * w+bias;
    }
    v = vec4(hash[1],hash[2],0.0,0.0);
    for (int i = 0; i < NUM_CHANNELS_ONE; i += 4) {
      w = mat4(
          texelFetch(weightsZero, ivec2(0, NUM_CHANNELS_ONE + i), 0),
          texelFetch(weightsZero, ivec2(0, NUM_CHANNELS_ONE + i + 1), 0),
          texelFetch(weightsZero, ivec2(0, NUM_CHANNELS_ONE + i + 2), 0),
          texelFetch(weightsZero, ivec2(0, NUM_CHANNELS_ONE + i + 3), 0)
      );
      result_one[i / 4] += v * w;
  }
  vec3 result;

  for (int i = 0; i < NUM_CHANNELS_ONE / 4; i++) {
      v = max(result_one[i], 0.0); // relu
      w = mat4(
          texelFetch(weightsOne, ivec2(0, i * 3), 0),
          texelFetch(weightsOne, ivec2(0, i * 3 + 1), 0),
          texelFetch(weightsOne, ivec2(0, i * 3 + 2), 0),
          vec4(0.0) // padding
      );
      if(i==0){
        bias=vec4(
            texelFetch(BiasOne, ivec2(0,0), 0).r,
            texelFetch(BiasOne, ivec2(0,1), 0).r,
            texelFetch(BiasOne, ivec2(0,2), 0).r,
            texelFetch(BiasOne, ivec2(0,3), 0).r
          );
      result += (v * w+bias).xyz;}
      else{
        result += (v * w).xyz;
      }
  }
    return 1.0 / (1.0 + exp(-result)); 
    //result = vec3(hash[0],hash[1],hash[2]);
    //return result;
}

void main() {    
  vec3 rayDirection = ( cameraPos-(modelPos*vec4( positionF, 1.0 )).rgb ); 
  vec3 rayDirection2 = ( cameraPos-(vec4( positionF, 1.0 )).rgb ); 

        float[3] hash_feature;
        vec3 Dir=(normalize(rayDirection));

        vec4 diffuse=texture(Diffuse,vUv);//float类型
        vec4 txyz=texture(hash1,vUv);
        
        diffuse=(diffuse);//4096
        hash_feature[0]     = txyz.r;
        hash_feature[1]     = txyz.g;
        hash_feature[2]     = txyz.b;

    if (mode == 1) { // diffuse
        pc_FragColor.rgb = diffuse.rgb;
    } else {
        if (mode == 2) { // specular
            pc_FragColor.rgb = evaluateNetwork(hash_feature, (Dir));
        } else { // full
            pc_FragColor.rgb = clamp((diffuse.rgb +evaluateNetwork(hash_feature, (Dir))), 0.0f, 1.0f);
        }
      }

    pc_FragColor.a = 1.0;  // 设置颜色的透明度为1(不透明）
    }
`;

    function createNetworkWeightTexture(network_weights) {
      let width = network_weights.length; //24
      let height = network_weights[0].length; //32

      console.log("宽度是", width);
      console.log("高度是", height);

      let weightsData = new Float32Array(width * height);
      for (let co = 0; co < height; co++) {
        for (let ci = 0; ci < width; ci++) {
          let index = co * width + ci; // column-major
          let weight = network_weights[ci][co];
          weightsData[index] = weight;
        }
      }

      let width_pad = width + (4 - (width % 4)); // make divisible by 4
      let weightsData_pad = new Float32Array(width_pad * height);
      for (let j = 0; j < width_pad; j += 4) {
        for (let i = 0; i < height; i++) {
          for (let c = 0; c < 4; c++) {
            if (c + j >= width) {
              weightsData_pad[j * height + i * 4 + c] = 0.0; // zero padding
            } else {
              weightsData_pad[j * height + i * 4 + c] =
                weightsData[j + i * width + c];
            }
          }
        }
      }

      let texture = new THREE.DataTexture(
        weightsData_pad,
        1,
        (width_pad * height) / 4,
        THREE.RGBAFormat,
        THREE.FloatType
      );
      texture.magFilter = THREE.NearestFilter;
      texture.minFilter = THREE.NearestFilter;
      texture.needsUpdate = true;
      // console.log("函数中的texture is: ",texture);
      return texture;
    }

    function createNetworkBias(network_bias) {
      let width = network_bias.length; //64,3
      // let height = network_weights[0].length; //32->64,3->3

      console.log("bias的长度是", width);
      // console.log('高度是',height)

      let weightsData = new Float32Array(width);

      for (let ci = 0; ci < width; ci++) {
        // let index = ci; // column-major
        // let weight = network_bias[ci];
        // weightsData[index] = weight;
        weightsData[ci] = network_bias[ci];
      }
      let width_pad;
      if (width % 4 != 0) {
        width_pad = width + (4 - (width % 4));
      } // make divisible by 4
      else {
        width_pad = width;
      }
      console.log("当前bisa填充后的长度", width_pad);
      let weightsData_pad = new Float32Array(width_pad);

      for (let i = 0; i < width_pad; i += 1) {
        if (i < width) {
          weightsData_pad[i] = weightsData[i];
        } else {
          weightsData_pad[i] = 0.0;
        }
      }
      console.log("当前的偏移未填充时如下", weightsData);
      console.log("当前的偏移填充如下", weightsData_pad);
      let texture = new THREE.DataTexture(
        weightsData_pad,
        1,
        width_pad,
        // THREE.RGBAFormat,
        THREE.RedFormat,
        THREE.FloatType
      );
      texture.magFilter = THREE.NearestFilter;
      texture.minFilter = THREE.NearestFilter;
      texture.needsUpdate = true;
      // console.log("函数中的texture is: ",texture);
      return texture;
    }

    function createViewDependenceFunctions(network_weights) {
      let channelsZero = network_weights['net.0.weight'].length;
      let channelsOne = network_weights['net.2.weight'].length;
      let channelsTwo = network_weights['net.2.weight'][0].length;
      // console.log('')
      console.log("[INFO] load MLP: ", channelsZero, channelsOne, channelsTwo);

      let RenderFragShader = RenderFragShader_template.replace(
        new RegExp("NUM_CHANNELS_ZERO", "g"),
        channelsZero
      );
      RenderFragShader = RenderFragShader.replace(
        new RegExp("NUM_CHANNELS_ONE", "g"),
        channelsOne
      );
      RenderFragShader = RenderFragShader.replace(
        new RegExp("NUM_CHANNELS_TWO", "g"),
        channelsTwo
      );

      return RenderFragShader;
    }

    let container,
      params,
      progressBar,
      progress,
      scene,
      camera,
      renderer,
      controls,
      stats,
      configs,
      sceneRef;

    // support changing scene name from url param
    // e.g. ?scene=lego&scene=chair
    //获取当前URL的值
    params = new URLSearchParams(new URL(window.location.href).searchParams);
    // let url = window.location.href;
    //记录当前页面的url
    // console.log(url);
    // document.getElementById("demo").innerHTML = url;

    const scene_names = params.getAll("scene");
    //传入场景的名称
    // const scene_names = "scene=lego&scene=chair&scene=bicycle";
    console.log(scene_names);
    // global config
    configs = {
      bg_color: (params.get("bg_color") === null) ? 0xffffff : parseInt(params.get("bg_color")), // default is white
      H: parseInt(params.get("H")) || Math.floor(0.95 * window.innerHeight),
      W: parseInt(params.get("W")) || Math.floor(0.99 * window.innerWidth),
      fovy: parseInt(params.get("fovy")) || 40,
      near: parseFloat(params.get("near")) || 0.01,
      far: parseFloat(params.get("far")) || 100,
      cameraState: params.get("cameraState"),
    };
    //记录config的值
    console.log(configs);
    function render() {
      renderer.setRenderTarget(null);
      renderer.render(scene, camera);
    }

    function animate() {
      requestAnimationFrame(animate);
      controls.update();
      render();
      stats.update();
    }

    //新的控制
    

    function initProgressBar(name, length) {
      progressBar = document.getElementById("progressBar");
      progress[name] = new Array(length).fill("🔴");
      progressBar.innerText = Object.keys(progress)
        .map((key) => progress[key].join(""))
        .join("|");
    }
    function updateProgressBar(name, index) {
      progressBar = document.getElementById("progressBar");
      progress[name][index] = "🟢";
      progressBar.innerText = Object.keys(progress)
        .map((key) => progress[key].join(""))
        .join("|");
    }

    function init() {
      console.log("[INFO] initialize...");

      // init webgl
      if (WebGL.isWebGL2Available() === false) {
        document.body.appendChild(WebGL.getWebGL2ErrorMessage());
        return;
      }

      // return error message if conf is empty
      if (Object.keys(scene_names).length === 0) {
        let e = document.createElement("p");
        e.style.cssText = "text-align: center; font-size: 28px;";
        e.innerHTML =
          "<b>Please provide at least one scene as URL parameters:</b> \
        ";
        document.body.appendChild(e);
        return;
      }

      // create renderer
      container = document.getElementById("container");

      renderer = new THREE.WebGLRenderer({
        powerPreference: "high-performance",
        precision: "mediump",
      });

      renderer.setPixelRatio(1);
      renderer.setSize(configs.W, configs.H);
      renderer.domElement.classList.add("renderer");
      container.appendChild(renderer.domElement);

      stats = new Stats();
      container.appendChild(stats.dom);

      // create camera
      camera = new THREE.PerspectiveCamera(configs.fovy,configs.W / configs.H,configs.near,configs.far);
      camera.position.x = 1;
      camera.position.y = 1;
      camera.position.z = 2;
   
      camera.up.set(0, 0, 1);

      controls = new OrbitControls(camera, renderer.domElement);
      // controls.enableDamping = true;
      // controls.screenSpacePanning = true;
      controls.minPolarAngle = Math.PI / 2.5; // 设置最小垂直旋转角度（以弧度为单位）
      controls.maxPolarAngle = Math.PI / 1.8; // 设置最大垂直旋转角度（以弧度为单位）
      controls.minAzimuthAngle =  Math.PI / 3.2; // 设置最小水平旋转角度（以弧度为单位）
      controls.maxAzimuthAngle = Math.PI /1.7; // 设置最大水平旋转角度（以弧度为单位）
      controls.maxDistance = 2.5
    
      // create scene
      scene = new THREE.Scene();
      sceneRef = {};

      // console.log(configs.bg_color);
      scene.background = new THREE.Color(configs.bg_color); // white background

      // window.addEventListener( 'resize', onWindowResize, false );

      // create GUI
      const gui = new GUI();

      gui.addColor(configs, "bg_color").onChange((v) => {
        scene.background = new THREE.Color(v);
      });

      gui.add(configs, "H", 64, Math.max(configs.H, 1024)).onChange((v) => {
        camera.aspect = configs.W / v;
        camera.updateProjectionMatrix();
        renderer.setSize(configs.W, v);
        render();
      });
      gui.add(configs, "W", 64, Math.max(configs.W, 1024)).onChange((v) => {
        camera.aspect = v / configs.H;
        camera.updateProjectionMatrix();
        renderer.setSize(v, configs.H);
        render();
      });
      gui.add(configs, "fovy", 0.001, 40).onChange((v) => {
        camera.fov = v;
        camera.updateProjectionMatrix();
        render();
      });
      gui.add(configs, "near", 0.001, 10).onChange((v) => {
        camera.near = v;
        camera.updateProjectionMatrix();
        render();
      });
      gui.add(configs, "far", 0.001, 1000).onChange((v) => {
        camera.far = v;
        camera.updateProjectionMatrix();
        render();
      });

      // load camera pose
      if (configs["cameraState"] !== null) {
        camera.matrix.fromArray(JSON.parse(configs["cameraState"]));
        camera.matrix.decompose(
          camera.position,
          camera.quaternion,
          camera.scale
        );
        camera.updateProjectionMatrix();
        controls.update();
      }

      // separate config per scene,不同场景不同的设置
      scene_names.forEach((name, index) => {
        configs[name] = {
          renderMode: 0, // rendering mode: 0 = full, 1 = diffuse, 2 = specular.
          pos_x: parseFloat(params.get(name + ".pos_x")) || 0,
          pos_y: parseFloat(params.get(name + ".pos_y")) || 0,
          pos_z: parseFloat(params.get(name + ".pos_z")) || 0,
          scale_x: parseFloat(params.get(name + ".scale_x")) || 1,
          scale_y: parseFloat(params.get(name + ".scale_y")) || 1,
          scale_z: parseFloat(params.get(name + ".scale_z")) || 1,
          rot_x: parseFloat(params.get(name + ".rot_x")) || 0,
          rot_y: parseFloat(params.get(name + ".rot_y")) || 0,
          rot_z: parseFloat(params.get(name + ".rot_z")) || 0,
        };
        const folder = gui.addFolder(name);
        folder
          .add(configs[name], "renderMode", {
            full: 0,
            diffuse: 1,
            specular: 2,
          })
          .onChange((v) => {
            sceneRef[name].forEach((object, index) => {
              object.traverse(function (child) {
                if (child.type == "Mesh") {
                  child.material.uniforms["mode"]["value"] = v;
                }
              });
            });
          });
        folder.add(configs[name], "pos_x", -10, 10).onChange((v) => {
          sceneRef[name].forEach((object, index) => {
            object.position.x = v;
          });
        });
        folder.add(configs[name], "pos_y", -10, 10).onChange((v) => {
          sceneRef[name].forEach((object, index) => {
            object.position.y = v;
          });
        });
        folder.add(configs[name], "pos_z", -10, 10).onChange((v) => {
          sceneRef[name].forEach((object, index) => {
            object.position.z = v;
          });
        });
        folder.add(configs[name], "scale_x", 0, 5).onChange((v) => {
          sceneRef[name].forEach((object, index) => {
            object.scale.x = v;
          });
        });
        folder.add(configs[name], "scale_y", 0, 5).onChange((v) => {
          sceneRef[name].forEach((object, index) => {
            object.scale.y = v;
          });
        });
        folder.add(configs[name], "scale_z", 0, 5).onChange((v) => {
          sceneRef[name].forEach((object, index) => {
            object.scale.z = v;
          });
        });
        folder.add(configs[name], "rot_x", 0, 180).onChange((v) => {
          sceneRef[name].forEach((object, index) => {
            object.rotation.x = (v / 180) * Math.PI;
          });
        });
        folder.add(configs[name], "rot_y", 0, 180).onChange((v) => {
          sceneRef[name].forEach((object, index) => {
            object.rotation.y = (v / 180) * Math.PI;
          });
        });
        folder.add(configs[name], "rot_z", 0, 360).onChange((v) => {
          sceneRef[name].forEach((object, index) => {
            object.rotation.z = (v / 180) * Math.PI;
          });
        });
        folder.close(); // collapsed by default
      });

      configs["save config URL"] = () => {
        // construct a URL string that repeat current configs
        let base = window.location.href.split("?")[0];
        function unwrap(x, prefix = "") {
          let res = [];
          for (const key of Object.keys(x)) {
            // leave out default values
            if (
              (key.includes("pos") && x[key] === 0) ||
              (key.includes("scale") && x[key] === 1) ||
              (key.includes("rot") && x[key] === 0) ||
              (key === "renderMode" && x[key] === 0)
            )
              continue;
            res.push(prefix + key + "=" + String(x[key]));
          }
          return res.join("&");
        }
        let res = [];
        for (const key of Object.keys(configs)) {
          if (
            key == "save config URL" ||
            (key === "fovy" && configs[key] === 60) ||
            (key === "near" && configs[key] === 0.01) ||
            (key === "far" && configs[key] === 100) ||
            (key === "bg_color" && configs[key] === 0xffffff)
          ) {
            continue;
          } else if (key == "cameraState") {
            res.push("cameraState=" + JSON.stringify(camera.matrix.toArray()));
          } else if (configs[key].constructor == Object) {
            res.push("scene=" + key);
            res.push(unwrap(configs[key], key + "."));
          } else {
            res.push(key + "=" + String(configs[key]));
          }
        }
        prompt("Copy to clipboard: Ctrl+C, Enter", base + "?" + res.join("&"));
      };

      gui.add(configs, "save config URL");

      // load all scenes async
      let promises = [];
      progress = {};

      // scene_names.forEach((name,index)=>console.log((name,index)));
      console.log("the name of the scene is: ", scene_names);

      // scene_names.forEach(name=>console.log(name));
      // scene_names = Array.from(scene_names);
      // scene_names.forEach((name,index)=>console.log((name)));
      // console.log("[INFO] test:");

      scene_names.forEach((name, index) => {
        promises.push(fetch(BASE + name + "/mlp.json").then((response) => {return response.json();})
            .catch((error) => {
              console.error("Error:", error);
            })
            .then((network_weights) => {
              console.log("[INFO] loading:", name);
              

              // check bound, load all meshes
              // let bound = network_weights["bound"];
              // let cascade = network_weights["cascade"];
              let cascade = 2; //存储到8张图片（每张图片4维）

              initProgressBar(name, cascade);
              sceneRef[name] = [];

              // for (let cas = 0; cas < cascade; cas++) {//多张图片的存储
              // load feature texture,漫反射材质与镜面反射材质

              let diffuse = new THREE.TextureLoader().load(
                BASE + name + "/diffusefe" + ".jpg",
                //BASE + name + "/diffusefe" + ".jpg",
                (object) => {
                  console.log("[INFO] loaded diffuse texture", BASE + name + "/diffusefe" + ".jpg");
                  updateProgressBar(name, 0);
                }
              );

              let tex1 = new THREE.TextureLoader().load(
                //BASE + name + "/specularfe" + ".jpg",
                BASE + name + "/specularfe" + ".jpg",
                (object) => {
                  console.log("[INFO] loaded specular texture", BASE + name + "/specularfe" + ".jpg");
                  updateProgressBar(name, 1);
                }
              );

              // console.log("the tex4 is: ", tex4);

              diffuse.magFilter = THREE.NearestFilter;
              diffuse.minFilter = THREE.NearestFilter;
              tex1.magFilter = THREE.NearestFilter;
              tex1.minFilter = THREE.NearestFilter;



              // load MLP
              let RenderFragShader = //将参数传入片段着色器
                createViewDependenceFunctions(network_weights);
              // console.log("片段着色器是: ", RenderFragShader);
              let weightsTexZero = createNetworkWeightTexture(
                network_weights["net.0.weight"]
              );
              console.log("weightsTexZero is: ", weightsTexZero);
              let weightsTexOne = createNetworkWeightTexture(
                network_weights["net.2.weight"]
              );
              console.log("weightsTexOne is: ", weightsTexOne);

              let weightsBiasZero = createNetworkBias(
                network_weights["net.0.bias"]
              );
              console.log("weightsBiasZero is: ", weightsBiasZero);

              let weightsBiasOne = createNetworkBias(
                network_weights["net.2.bias"]
              );
              console.log("weightsBiasOne is: ", weightsBiasOne);

              let newmat = new THREE.RawShaderMaterial({
                side: THREE.DoubleSide,
                vertexShader: RenderVertShader,
                fragmentShader: RenderFragShader,
                uniforms: {
                  mode: { value: configs[name].renderMode },
                  // tDiffuse: { value: tex0 },
                  // tSpecular: { value: tex1 },
                  // hash:{value:tex},//加载的hash特征

                  Diffuse: { value: diffuse },
                  // hash0:{value:tex0},
                  hash1: { value: tex1 },
                  weightsZero: { value: weightsTexZero },
                  weightsOne: { value: weightsTexOne },
                  BiasZero: { value: weightsBiasZero },
                  BiasOne: { value: weightsBiasOne },
                },
                glslVersion: THREE.GLSL3,
              });
              console.log("渲染的颜色材质 ", newmat);

              // load obj
              let obj_mesh = new OBJLoader().load(BASE + name + "/mesh_0" + ".obj",object => {
                  object.traverse(function (child) {
                    if (child.type == "Mesh") {
                      child.material = newmat;
                    }
                  });
                  console.log("[INFO] loaded mesh:", name);
                  updateProgressBar(name, 8*3);
                  object.position.set(
                    configs[name].pos_x,
                    configs[name].pos_y,
                    configs[name].pos_z
                  );
                  object.scale.set(
                    configs[name].scale_x,
                    configs[name].scale_y,
                    configs[name].scale_z
                  );
                  object.rotation.set(
                    (configs[name].rot_x / 180) * Math.PI,
                    (configs[name].rot_y / 180) * Math.PI,
                    (configs[name].rot_z / 180) * Math.PI
                  );
                  sceneRef[name].push(object);
                  scene.add(object);
                }
              );
              console.log("加载的obj文件是: ", obj_mesh);
            })
            .catch((error) => {
              console.error("Error:", error);
            })
        );
      });

      Promise.all(promises).then((response) => {
        console.log("[INFO] start animation!");
        animate();
      });
    }

    init();
  </script>
</html>
